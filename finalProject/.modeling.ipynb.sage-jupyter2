{"backend_state":"init","connection_file":"/projects/183af3d5-8548-4a20-9a82-38842b87480b/.local/share/jupyter/runtime/kernel-4dc17ff6-25d9-406b-b9ad-bdbb5b21ab21.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"d4eeda","input":"# Calculate value to impute with\n# Impute with the mean\n\ndf = data\n\ndf['ph'].fillna(int(df['ph'].mean()), inplace=True)\n\ndf['Sulfate'].fillna(int(df['Sulfate'].mean()), inplace=True)\n\ndf['Trihalomethanes'].fillna(int(df['Trihalomethanes'].mean()), inplace=True)\n\ndata.head(10)\n","pos":18,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"e5ba2e","input":"# Y_pred = model.predict(X_test)\n# print(\"Accuracy:\", metrics.accuracy_score(Y_test, Y_pred))\n# print(\"Precision:\", metrics.precision_score(Y_test, Y_pred))\n# print(\"Recall:\", metrics.recall_score(Y_test, Y_pred))\n# print(\"Mean-Squared-Error:\", mean_squared_error)","pos":22,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"892db1","input":"# classification_report(y_test, y_hat_dtc, output_dict = True)\nprint(data[data[\"Potability\"] == 0].shape[0])\nprint(data[data[\"Potability\"] == 1].shape[0])","output":{"0":{"name":"stdout","output_type":"stream","text":"811\n811\n"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"9111b5","input":"from pandas import read_csv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.svm import SVC","pos":16,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"377d3c","input":"\n# model = SVC()\n# model.fit(X_train, Y_train)\n# #mean_squared_error = (np.sum((y_test - y_hat)**2))/len(y_test)","pos":21,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"4e28aa","input":"# D = data.values\n# x = D[:,0:4]\n# y = D[:, 4]\n# X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.20)","pos":20,"type":"cell"}
{"cell_type":"code","exec_count":56,"id":"8d5d5f","input":"#Impute with the most common number\n\ndf['ph'].fillna(df['ph'].replace(7.0), inplace=True)\n\ndf['Sulfate'].fillna(df['Sulfate'].replace(333.0), inplace=True)\n\ndf['Trihalomethanes'].fillna(df['Trihalomethanes'].replace(66.0), inplace=True)\n\ndata.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ph</th>\n      <th>Hardness</th>\n      <th>Solids</th>\n      <th>Chloramines</th>\n      <th>Sulfate</th>\n      <th>Conductivity</th>\n      <th>Organic_carbon</th>\n      <th>Trihalomethanes</th>\n      <th>Turbidity</th>\n      <th>Potability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.000000</td>\n      <td>204.890455</td>\n      <td>20791.318981</td>\n      <td>7.300212</td>\n      <td>368.516441</td>\n      <td>564.308654</td>\n      <td>10.379783</td>\n      <td>86.990970</td>\n      <td>2.963135</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.716080</td>\n      <td>129.422921</td>\n      <td>18630.057858</td>\n      <td>6.635246</td>\n      <td>333.000000</td>\n      <td>592.885359</td>\n      <td>15.180013</td>\n      <td>56.329076</td>\n      <td>4.500656</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.099124</td>\n      <td>224.236259</td>\n      <td>19909.541732</td>\n      <td>9.275884</td>\n      <td>333.000000</td>\n      <td>418.606213</td>\n      <td>16.868637</td>\n      <td>66.420093</td>\n      <td>3.055934</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.316766</td>\n      <td>214.373394</td>\n      <td>22018.417441</td>\n      <td>8.059332</td>\n      <td>356.886136</td>\n      <td>363.266516</td>\n      <td>18.436524</td>\n      <td>100.341674</td>\n      <td>4.628771</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.092223</td>\n      <td>181.101509</td>\n      <td>17978.986339</td>\n      <td>6.546600</td>\n      <td>310.135738</td>\n      <td>398.410813</td>\n      <td>11.558279</td>\n      <td>31.997993</td>\n      <td>4.075075</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n0  7.000000  204.890455  20791.318981     7.300212  368.516441    564.308654   \n1  3.716080  129.422921  18630.057858     6.635246  333.000000    592.885359   \n2  8.099124  224.236259  19909.541732     9.275884  333.000000    418.606213   \n3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n\n   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n0       10.379783        86.990970   2.963135           0  \n1       15.180013        56.329076   4.500656           0  \n2       16.868637        66.420093   3.055934           0  \n3       18.436524       100.341674   4.628771           0  \n4       11.558279        31.997993   4.075075           0  "},"exec_count":56,"output_type":"execute_result"}},"pos":19,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":81,"id":"52316c","input":"predictions = grid_kn.predict(x_test)","pos":4,"type":"cell"}
{"cell_type":"code","exec_count":82,"id":"6adf69","input":"y_test.value_counts()","output":{"0":{"data":{"text/plain":"0    497\n1    322\nName: Potability, dtype: int64"},"exec_count":82,"output_type":"execute_result"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":83,"id":"f9772c","input":"print(target.shape[0])\nprint(features.shape[0])","output":{"0":{"name":"stdout","output_type":"stream","text":"3276\n3276\n"}},"pos":6,"type":"cell"}
{"cell_type":"code","exec_count":84,"id":"ce13c1","input":"from sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.model_selection import GridSearchCV\nparameters = {\n    \"n_neighbors\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n}\n\nmy_KNN_model = GridSearchCV(KNN(), param_grid = parameters)\nmy_KNN_model.fit(x_train, y_train)\nmy_KNN_model.best_params_","output":{"0":{"data":{"text/plain":"{'n_neighbors': 2}"},"exec_count":84,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":85,"id":"8a67d3","input":"KNN_model_2 = KNN(n_neighbors = 12)\nKNN_model_2.fit(x_train, y_train)\nfrom sklearn.metrics import f1_score\n\n\ny_hat = KNN_model_2.predict(x_test)\nmean_squared_error = (np.sum((y_test - y_hat)**2))/len(y_test)\nprint(mean_squared_error)\nprint(KNN_model_2.score(x_test,y_test))\nsns.heatmap(confusion_matrix(y_test, y_hat), annot = True, fmt ='g')\nscore = f1_score(y_test, y_hat, average='binary')\nprint(score)\n","output":{"0":{"name":"stdout","output_type":"stream","text":"0.40415140415140416\n0.5958485958485958\n0.20240963855421687\n"},"1":{"data":{"image/png":"815a9c3a8ebf8d3d949f0e1a22b12a70a98a292c","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":85,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":89,"id":"2a1490","input":"from sklearn.tree import DecisionTreeClassifier\n\ndtc_param = {\n    'max_depth': [1,2,3,4,5,6,7,8,9,10],\n    'max_leaf_nodes': [20,30,40,50,60,70]\n}\n\ndtc_test = GridSearchCV(DecisionTreeClassifier(), param_grid = dtc_param).fit(x_train,y_train)\ndtc_test.best_params_","output":{"0":{"data":{"text/plain":"{'max_depth': 9, 'max_leaf_nodes': 50}"},"exec_count":89,"output_type":"execute_result"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":90,"id":"70d682","input":"\n\ndtc_model = DecisionTreeClassifier(max_depth = 3, max_leaf_nodes = 70).fit(x_train,y_train)\ny_hat_dtc = dtc_model.predict(x_test)\nmean_squared_error = (np.sum((y_test - y_hat_dtc)**2))/len(y_test)\nprint(mean_squared_error)\nprint(dtc_model.score(x_test,y_test))\nprint(classification_report(y_test, y_hat_dtc))\nsns.heatmap(confusion_matrix(y_test, y_hat_dtc), annot = True, fmt ='g')","output":{"0":{"name":"stdout","output_type":"stream","text":"0.3907203907203907\n0.6092796092796092\n              precision    recall  f1-score   support\n\n           0       0.62      0.93      0.74       497\n           1       0.51      0.12      0.20       322\n\n    accuracy                           0.61       819\n   macro avg       0.57      0.52      0.47       819\nweighted avg       0.58      0.61      0.53       819\n\n"},"1":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":90,"output_type":"execute_result"},"2":{"data":{"image/png":"9d516d0bc3bbed1746bbe6037f829bbda1488520","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":90,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":14,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":92,"id":"015332","input":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nrfc_param = {\n    \"n_estimators\": [100,120,140,160,180,200],\n    \"max_features\": [\"log2\", \"sqrt\", None],\n    \"min_samples_split\": [10,20,30,40]\n}\n\nrfc_test = GridSearchCV(RandomForestClassifier(), param_grid = rfc_param).fit(x_train,y_train)\nrfc_test.best_params_","output":{"0":{"data":{"text/plain":"{'max_features': None, 'min_samples_split': 10, 'n_estimators': 180}"},"exec_count":92,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":93,"id":"bde8d9","input":"rfc_model = RandomForestClassifier(max_features=None,\n                                   min_samples_split=20,\n                                   n_estimators=140).fit(x_train, y_train)\ny_hat_rfc = rfc_model.predict(x_test)\nmean_squared_error = (np.sum((y_test - y_hat_rfc)**2)) / len(y_test)\nprint(mean_squared_error)\nprint(rfc_model.score(x_test, y_test))\nprint(classification_report(y_test, y_hat_rfc))\nsns.heatmap(confusion_matrix(y_test, y_hat_rfc), annot=True, fmt='g')","output":{"0":{"name":"stdout","output_type":"stream","text":"0.31135531135531136\n0.6886446886446886\n              precision    recall  f1-score   support\n\n           0       0.69      0.89      0.78       497\n           1       0.69      0.38      0.49       322\n\n    accuracy                           0.69       819\n   macro avg       0.69      0.63      0.63       819\nweighted avg       0.69      0.69      0.66       819\n\n"},"1":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":93,"output_type":"execute_result"},"2":{"data":{"image/png":"7d85f443ed918d30a1f0c27985773390bc333688","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":93,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":94,"id":"ca744f","input":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\ndata = pd.read_csv(\"./Data/water_potability.csv\")\n\ndf['ph'].fillna(df['ph'].replace(7.0), inplace=True)\ndf['Sulfate'].fillna(df['Sulfate'].replace(333.0), inplace=True)\ndf['Trihalomethanes'].fillna(df['Trihalomethanes'].replace(66.0), inplace=True)\n\n#df = data\n#df['ph'].fillna(int(df['ph'].mean()), inplace=True)\n#df['Sulfate'].fillna(int(df['Sulfate'].mean()), inplace=True)\n#df['Trihalomethanes'].fillna(int(df['Trihalomethanes'].mean()), inplace=True)\n\n\n# '''\n# data.dropna(axis=0, inplace = True)\n\n\n# n = abs(data[data[\"Potability\"] == 0].shape[0]- data[data[\"Potability\"] == 1].shape[0])\n# data_filtered = data[data[\"Potability\"]==0];\n# data_filtered2 = data[data[\"Potability\"] == 1]\n# data_filtered = data.drop(index=data_filtered.index[:n], axis=0, inplace=True)\n# frames = [data_filtered,data_filtered2]\n\n# data_equal = pd.concat(frames)\n\n# '''\n\n\n# #try changing data to data_equal for some models --> see if it gets better results -Annya\n\n# # Try with imputed data (try with mean, mode (most common value), etc.)\n# # GridSearchCV\n\ndata.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ph</th>\n      <th>Hardness</th>\n      <th>Solids</th>\n      <th>Chloramines</th>\n      <th>Sulfate</th>\n      <th>Conductivity</th>\n      <th>Organic_carbon</th>\n      <th>Trihalomethanes</th>\n      <th>Turbidity</th>\n      <th>Potability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>204.890455</td>\n      <td>20791.318981</td>\n      <td>7.300212</td>\n      <td>368.516441</td>\n      <td>564.308654</td>\n      <td>10.379783</td>\n      <td>86.990970</td>\n      <td>2.963135</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.716080</td>\n      <td>129.422921</td>\n      <td>18630.057858</td>\n      <td>6.635246</td>\n      <td>NaN</td>\n      <td>592.885359</td>\n      <td>15.180013</td>\n      <td>56.329076</td>\n      <td>4.500656</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.099124</td>\n      <td>224.236259</td>\n      <td>19909.541732</td>\n      <td>9.275884</td>\n      <td>NaN</td>\n      <td>418.606213</td>\n      <td>16.868637</td>\n      <td>66.420093</td>\n      <td>3.055934</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.316766</td>\n      <td>214.373394</td>\n      <td>22018.417441</td>\n      <td>8.059332</td>\n      <td>356.886136</td>\n      <td>363.266516</td>\n      <td>18.436524</td>\n      <td>100.341674</td>\n      <td>4.628771</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.092223</td>\n      <td>181.101509</td>\n      <td>17978.986339</td>\n      <td>6.546600</td>\n      <td>310.135738</td>\n      <td>398.410813</td>\n      <td>11.558279</td>\n      <td>31.997993</td>\n      <td>4.075075</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n\n   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n0       10.379783        86.990970   2.963135           0  \n1       15.180013        56.329076   4.500656           0  \n2       16.868637        66.420093   3.055934           0  \n3       18.436524       100.341674   4.628771           0  \n4       11.558279        31.997993   4.075075           0  "},"exec_count":94,"output_type":"execute_result"}},"pos":1,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":95,"id":"af4d86","input":"target = data[\"Potability\"]\nfeatures = data.drop(columns = [\"Potability\"], axis = 1)\nx_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.25)","pos":2,"type":"cell"}
{"cell_type":"code","exec_count":96,"id":"7c0719","input":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nkn = KNeighborsClassifier()\n\"\"\"params = {\n    'n_neighbors' : [5, 25],\n    'weights': ['uniform', 'distance'],\n    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n}\ngrid_kn = GridSearchCV(estimator = kn,param_grid = params,scoring = 'accuracy', cv = 5, verbose = 1,n_jobs = -1)\ngrid_kn.fit(x_train, y_train)\nprint(grid_kn.best_params_)\nKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',metric_params=None, n_jobs=-1, n_neighbors=5, p=2, weights='uniform')\nprint(grid_kn.score(x_test, y_test)) \"\"\"\nparams = {\n    'n_neighbors' : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n}\ngrid_kn = GridSearchCV(estimator = kn,param_grid = params,scoring = 'accuracy', verbose = 1,n_jobs = -1)\ngrid_kn.fit(x_train, y_train)\nprint(grid_kn.best_params_)\nKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',metric_params=None, n_jobs=-1, n_neighbors=5, p=2, weights='uniform')\nprint(grid_kn.score(x_test, y_test)) ","output":{"0":{"name":"stdout","output_type":"stream","text":"Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"},"1":{"ename":"ValueError","evalue":"\nAll the 75 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n75 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\", line 200, in fit\n    return self._fit(X, y)\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 407, in _fit\n    X, y = self._validate_data(\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m15\u001b[39m]\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     17\u001b[0m grid_kn \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m kn,param_grid \u001b[38;5;241m=\u001b[39m params,scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mgrid_kn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_kn\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     20\u001b[0m KNeighborsClassifier(algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, leaf_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski\u001b[39m\u001b[38;5;124m'\u001b[39m,metric_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: \nAll the 75 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n75 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\", line 200, in fit\n    return self._fit(X, y)\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 407, in _fit\n    X, y = self._validate_data(\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"/projects/183af3d5-8548-4a20-9a82-38842b87480b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"]}},"pos":3,"type":"cell"}
{"cell_type":"markdown","id":"0085b3","input":"#### K\\-Nearest Neighbors\n\nAccuracy = \\(Before, 60%\\), \\(Using Mean, 59%\\), \\(Using Using the most common number, \\)\n\n### Random Forest Classifier\n\nAccuracy = \\(Before,  66%\\), \\(Using Mean, 68%\\), \\(Using Using the most common number, 69%\\)\n\n### Decision Tree Classifier\n\nAccuracy = \\(Before,  70%\\), \\(Using Mean, 63%\\), \\(Using Using the most common number, 61%\\)\n\n","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"168a65","input":"### DecisionTreeClassifier\n\n","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"9b5058","input":"### imputations\n\n","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"c4de2a","input":"### RandomForestClassifier\n\n","pos":9,"type":"cell"}
{"id":0,"time":1657736723215,"type":"user"}
{"last_load":1657732236762,"type":"file"}